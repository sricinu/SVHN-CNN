{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqNLP_Project1_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.14"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sricinu/SVHN-CNN/blob/master/R9/Assignment/SeqNLP_Project1_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bASOSZZoljT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0df5ea4e-1b59-41c3-f5ee-49cf3a6b1d81"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "vocab_size = 10000 #vocab size\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency.\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n",
            "17473536/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCPC_WN-eCyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMEsHYrWxdtk",
        "colab_type": "text"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0g381XzeCyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy6n-uM2eCy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhMAgaNeCy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dybtUgUReCy8",
        "colab_type": "text"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OLM4eBeCy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "171c1171-0ac0-49f5-ac2e-97757661d450"
      },
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vecor_length, input_length=maxlen))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=64)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1027 09:46:52.737495 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1027 09:46:52.749437 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1027 09:46:52.756747 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1027 09:46:53.042542 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W1027 09:46:53.061638 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W1027 09:46:53.067704 139773964310400 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 373,301\n",
            "Trainable params: 373,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W1027 09:46:53.877000 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W1027 09:46:53.989286 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "W1027 09:46:54.061121 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1027 09:46:54.067235 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W1027 09:46:54.068512 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W1027 09:46:55.350878 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W1027 09:46:55.352703 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "W1027 09:46:55.504472 139773964310400 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 319s 13ms/step - loss: 0.4245 - acc: 0.7996 - val_loss: 0.3332 - val_acc: 0.8617\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 315s 13ms/step - loss: 0.2611 - acc: 0.8982 - val_loss: 0.3319 - val_acc: 0.8722\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 317s 13ms/step - loss: 0.2042 - acc: 0.9227 - val_loss: 0.4284 - val_acc: 0.8500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f422a39d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxNDNhrseCzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3CSVVPPeCzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igq8Qm8GeCzG",
        "colab_type": "text"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AqOnLa2eCzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70681bfa-af0c-45fe-ccee-c8cd86874e6f"
      },
      "source": [
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dUDSg7VeCzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "dcb6b03b-39fe-4190-f3d6-4ebeb0b84189"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "inp = model.input                                           # input placeholder\n",
        "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
        "\n",
        "# Testing\n",
        "test = np.random.random(vocab_size)[np.newaxis,...]\n",
        "layer_outs = functor([test, 1.])\n",
        "print layer_outs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[[0.05659012, 0.03255663, 0.05259479, ..., 0.04475576,\n",
            "         0.05590658, 0.01284954],\n",
            "        [0.05659012, 0.03255663, 0.05259479, ..., 0.04475576,\n",
            "         0.05590658, 0.01284954],\n",
            "        [0.05659012, 0.03255663, 0.05259479, ..., 0.04475576,\n",
            "         0.05590658, 0.01284954],\n",
            "        ...,\n",
            "        [0.05659012, 0.03255663, 0.05259479, ..., 0.04475576,\n",
            "         0.05590658, 0.01284954],\n",
            "        [0.05659012, 0.03255663, 0.05259479, ..., 0.04475576,\n",
            "         0.05590658, 0.01284954],\n",
            "        [0.05659012, 0.03255663, 0.05259479, ..., 0.04475576,\n",
            "         0.05590658, 0.01284954]]], dtype=float32), array([[-1.6546853e-02,  3.1401835e-02,  1.5649883e-02,  1.5632128e-02,\n",
            "         2.3145592e-02,  5.6794476e-02, -4.6023242e-03,  1.7936165e-02,\n",
            "         5.9178345e-02, -3.7832137e-02,  6.1010927e-02,  9.1738123e-03,\n",
            "         3.0579679e-02,  1.4780810e-02, -4.1518152e-02, -4.3375526e-02,\n",
            "         3.3200830e-02,  4.4807695e-02, -5.5562351e-02,  2.1517411e-02,\n",
            "        -1.2223183e-02,  5.5891164e-02,  5.8561817e-02,  2.4927512e-02,\n",
            "        -1.0968993e-02, -4.2719942e-02, -3.6417462e-02,  6.1055306e-02,\n",
            "         7.1833037e-02, -3.1903360e-02, -4.5838527e-04,  7.0066758e-02,\n",
            "        -9.5975678e-04,  1.1776628e-02, -1.4284794e-02, -2.9428795e-03,\n",
            "         2.3735261e-02, -3.5667494e-02,  2.1232564e-02, -7.8140453e-02,\n",
            "         1.1718895e-02,  1.3691785e-02, -5.5882882e-02,  1.8421326e-02,\n",
            "         2.7969744e-02, -4.7469243e-02, -2.2133829e-02, -5.6053270e-02,\n",
            "         2.0235235e-02,  2.9836109e-02, -3.5322497e-03,  7.6093867e-02,\n",
            "         8.6144552e-02, -6.1542224e-02,  7.8066834e-03,  3.5774156e-03,\n",
            "        -1.6336458e-02,  8.3135456e-02,  1.1105707e-02, -3.8490441e-02,\n",
            "        -8.6669721e-02, -6.4339817e-02,  3.8485192e-02, -4.6384487e-02,\n",
            "         5.9044757e-04,  7.1380660e-02, -3.7829403e-02, -4.1125983e-02,\n",
            "        -1.4578749e-02,  3.6769550e-02,  3.8083985e-03, -2.3021866e-02,\n",
            "         1.1982337e-02,  4.3024011e-02,  4.7758359e-02, -5.3842179e-03,\n",
            "         8.0614695e-03,  8.3190498e-05, -2.6601361e-02, -2.6723358e-03,\n",
            "         1.2862823e-02, -3.4898499e-03, -3.6678225e-02, -3.8092881e-02,\n",
            "        -6.7212716e-02, -1.9052502e-02,  1.3400525e-01, -4.5111850e-02,\n",
            "        -3.8461767e-02, -8.7738879e-02,  1.8858908e-02, -5.0922178e-02,\n",
            "        -1.6845973e-02,  7.3390253e-02, -9.6497938e-02,  2.0813504e-02,\n",
            "         5.4980549e-03, -3.8495351e-02, -2.6754351e-02,  1.1225616e-02]],\n",
            "      dtype=float32), array([[0.6292809]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tskt_1npeCzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}